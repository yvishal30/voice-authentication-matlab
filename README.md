# voice-authentication-matlab
A deep-learning based Speaker Recognition system using MFCC features, CNN/LSTM models, and VoxCeleb dataset, with complete pipeline for preprocessing, training, evaluation, and custom dataset handling.

# ğŸ”Š **Speaker Recognition Using Deep Learning**

A deep learning pipeline for **speaker identification** and **speaker verification** using MFCC feature extraction, neural networks (CNN/LSTM), and audio preprocessing on large-scale datasets like **VoxCeleb**.

This project includes:

âœ” Audio preprocessing
âœ” Feature extraction
âœ” Dataset creation
âœ” Custom ODataset
âœ” Speaker classification model
âœ” Training & evaluation pipeline
âœ” WAV/Subset datasets
âœ” Ready-to-run scripts

---

## ğŸ“ **Folder Structure**

```
ğŸ“¦ Speaker-Recognition-Project/
â”‚
â”œâ”€â”€ dataset_subset/        # Smaller cleaned dataset (processed clips)
â”œâ”€â”€ dataset_wav/           # Raw WAV files
â”œâ”€â”€ models/                # Trained model weights (.pth)
â”œâ”€â”€ ODataset/              # Custom dataset class implementation
â”œâ”€â”€ scripts/               # Preprocessing + training + evaluation code
â”‚
â””â”€â”€ README.md
```

---

## ğŸ¯ **Project Objective**

To build an efficient speaker recognition system capable of identifying a speakerâ€™s identity from voice samples using neural network models and audio feature engineering.

## **Working Video**
https://drive.google.com/file/d/1zojf5Du85wSGxKVhdgsEekbxiLEKMRi8/view?usp=sharing 

## ğŸ§  **Features**

### ğŸ”¹ **1. Audio Preprocessing**

* Silence removal
* WAV normalization
* Resampling (16 kHz)
* Segment extraction

### ğŸ”¹ **2. Feature Extraction**

* MFCC
* Mel Spectrogram
* Log-Mel Features

### ğŸ”¹ **3. Deep Learning Model**

* CNN / LSTM / Hybrid network
* Softmax classification head
* CrossEntropy loss

### ğŸ”¹ **4. Dataset Management**

* VoxCeleb integration
* Custom ODataset for training
* Dataset subset support
* Automatic speaker ID mapping

### ğŸ”¹ **5. Training Pipeline**

* Batch loading
* Validation set
* Learning rate scheduling

### ğŸ”¹ **6. Evaluation**

* Accuracy
* Loss curves
* Confusion matrix
* Prediction on test samples

# ğŸ“¥ **Dataset Download**

The project supports **VoxCeleb1** dataset.

### **ğŸ”— Official VoxCeleb Dataset Link:**

ğŸ‘‰ [https://www.robots.ox.ac.uk/~vgg/data/voxceleb/](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/)

### **Includes:**

* VoxCeleb1
* VoxCeleb2
* Metadata & speaker lists
* Audio files in WAV/M4A

## ğŸ› ï¸ **Installation & Setup**

### âœ” Clone the repository

```bash
git clone https://github.com/your-username/speaker-recognition.git
cd speaker-recognition
```

### âœ” Create virtual environment

```bash
python -m venv venv
source venv/bin/activate     # Linux/Mac
venv\Scripts\activate        # Windows
```

### âœ” Install dependencies

```bash
pip install -r requirements.txt
```

## ğŸ“Œ **Usage**

### âœ” **1. Preprocess Dataset**

```bash
python scripts/preprocess_audio.py --dataset dataset_wav --output dataset_subset
```

### âœ” **2. Extract Features**

```bash
python scripts/extract_features.py --input dataset_subset --output features/
```

### âœ” **3. Train Model**

```bash
python scripts/train.py --dataset dataset_subset --epochs 50 --batch 32
```

### âœ” **4. Evaluate Model**

```bash
python scripts/evaluate.py --model models/best_model.pth --dataset dataset_subset
```

### âœ” **5. Test With Custom Audio**

```bash
python scripts/predict.py --audio sample.wav
```

## ğŸ“Š **Expected Results**

* 80â€“95% accuracy depending on dataset size
* Good performance on VoxCeleb subset
* Real-time speaker prediction with optimized model

## ğŸ“ˆ **Future Enhancements**

* Implement **Speaker Verification (Siamese Networks)**
* Add **X-Vectors** or **ECAPA-TDNN embeddings**
* Add Web Interface (Flask/React)
* Deploy on cloud GPU
* Live microphone inference

